{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231cb5d6",
   "metadata": {},
   "source": [
    "# Inference InternVL3-4B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a046ba",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2025/youssef.sidhom/Object_detection_in_documents/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "MODEL_ID = \"OpenGVLab/InternVL3_5-4B-HF\"\n",
    "\n",
    "# Load with bfloat16 to fit nicely in 20GB\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_ID, \n",
    "    dtype=torch.bfloat16, # Use torch_dtype instead of .to() later\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,      # Required for InternVL models\n",
    "    attn_implementation=\"eager\"\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True, use_fast=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea4580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_vl_utils import process_vision_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1a96a",
   "metadata": {},
   "source": [
    "### Methods for manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15aed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_inference_internvl(model, tokenizer, image_path, prompt, max_num=12):\n",
    "    # 1. Use your existing load_image logic\n",
    "    # This returns a tensor of shape [num_tiles, 3, 448, 448]\n",
    "    pixel_values = load_image(image_path, max_num=max_num).to(torch.bfloat16).cuda()\n",
    "    \n",
    "    # 2. Preparation for inference\n",
    "    # InternVL needs the <image> token to know where to 'inject' the visual features\n",
    "    question = f'<image>\\n{prompt}'\n",
    "    generation_config = dict(max_new_tokens=1024, do_sample=True)\n",
    "\n",
    "    # 3. Inference using the InternVL chat API\n",
    "    # This handles the internal chat templates and tokenization for you\n",
    "    response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "    \n",
    "    # 4. Calculate 'Input' dimensions (The canvas size)\n",
    "    # InternVL stitches tiles into a grid. We calculate the grid dimensions:\n",
    "    img = Image.open(image_path)\n",
    "    aspect_ratio = img.width / img.height\n",
    "    \n",
    "    # Re-calculate the target ratio to find the final grid dimensions\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(1, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= 1)\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, img.width, img.height, 448)\n",
    "    \n",
    "    # Final 'canvas' size the model operated on\n",
    "    input_width = target_aspect_ratio[0] * 448\n",
    "    input_height = target_aspect_ratio[1] * 448\n",
    "    \n",
    "    return response, input_height, input_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff09570",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InternVLModel' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<image>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetect all signatures and return their locations and labels in the form of coordinates.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mzero_shot_inference_internvl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/images/test_arz92e00_jpg.rf.d032a45166eda3a7b6ca41c47bde7d69_orig.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDescribe the layout of the document.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m, in \u001b[0;36mzero_shot_inference_internvl\u001b[0;34m(model, tokenizer, image_path, prompt, max_num)\u001b[0m\n\u001b[1;32m      9\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 3. Inference using the InternVL chat API\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# This handles the internal chat templates and tokenization for you\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m(tokenizer, pixel_values, question, generation_config)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 4. Calculate 'Input' dimensions (The canvas size)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# InternVL stitches tiles into a grid. We calculate the grid dimensions:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n",
      "File \u001b[0;32m~/Object_detection_in_documents/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InternVLModel' object has no attribute 'chat'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question = '<image>\\nDetect all signatures and return their locations and labels in the form of coordinates.'\n",
    "zero_shot_inference_internvl(model, tokenizer, 'data/images/test_arz92e00_jpg.rf.d032a45166eda3a7b6ca41c47bde7d69_orig.jpg', \"Describe the layout of the document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690b381",
   "metadata": {},
   "source": [
    "Tool for inference zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc04a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedab0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the max number of tiles in `max_num`\n",
    "pixel_values = load_image('data/images/test_arz92e00_jpg.rf.d032a45166eda3a7b6ca41c47bde7d69_orig.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=True)\n",
    "\n",
    "# single-image single-round conversation (单图单轮对话)\n",
    "question = '<image>\\nDetect all signatures and return their locations and labels in the form of coordinates.'\n",
    "response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa84190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_inference(model, processor, image, prompt):\n",
    "  messages = [\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\n",
    "                  \"type\": \"image\",\n",
    "                  \"image\": image,\n",
    "              },\n",
    "              {\"type\": \"text\", \"text\": prompt},\n",
    "          ],\n",
    "      }\n",
    "  ]\n",
    "  # Preparation for inference\n",
    "  text = processor.apply_chat_template(\n",
    "      messages, tokenize=False, add_generation_prompt=True\n",
    "  )\n",
    "  image_inputs, video_inputs = process_vision_info(messages)\n",
    "  inputs = processor(\n",
    "      text=[text],\n",
    "      images=image_inputs,\n",
    "      videos=video_inputs,\n",
    "      padding=True,\n",
    "      return_tensors=\"pt\",\n",
    "  )\n",
    "  inputs = inputs.to(\"cuda\")\n",
    "  # Inference: Generation of the output\n",
    "  generated_ids = model.generate(**inputs, max_new_tokens=1024)\n",
    "  generated_ids_trimmed = [\n",
    "      out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "  ]\n",
    "  output_text = processor.batch_decode(\n",
    "      generated_ids_trimmed, do_sample=True, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "  )[0]\n",
    "  input_height = inputs['image_grid_thw'][0][1]*14\n",
    "  input_width = inputs['image_grid_thw'][0][2]*14\n",
    "  return output_text, input_height, input_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0fe08",
   "metadata": {},
   "source": [
    "For visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e213520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "def plot_bounding_boxes(image, bbox_data, height, width,Ground_T):\n",
    "  image = image.resize((width, height))\n",
    "  # Parse the JSON input\n",
    "  # Plot the image\n",
    "  fig, ax = plt.subplots(1)\n",
    "  ax.imshow(image)\n",
    "  ax.axis('off')\n",
    "  # Plot the bounding boxes and labels\n",
    "  for item in bbox_data:\n",
    "      bbox = item['bbox_2d']\n",
    "      label = item['label']\n",
    "      rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], linewidth=2, edgecolor='r', facecolor='none',label='Prediction')\n",
    "      ax.add_patch(rect)\n",
    "      plt.text(bbox[0], bbox[1] - 10, label, color='r', fontsize=10)\n",
    "  for item in Ground_T:\n",
    "    rect = patches.Rectangle((item[0], item[1]), item[2] - item[0], item[3] - item[1], linewidth=2, edgecolor='g', facecolor='none',label='Ground Truth')\n",
    "    ax.add_patch(rect)\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1ca12",
   "metadata": {},
   "source": [
    "### Metrics used to evalute performance\n",
    "- Hard evaluation metrics: \n",
    "    - IoU: The standard academic benchmark.\n",
    "- Soft evaluation metrics:\n",
    "    - Iop: Intersection over prediction, how much of your predicted box is inside the ground Truth\n",
    "    - Center-point hit: if the center of the predicted box is inside the center \n",
    "    - Center distance error: The distance between the center of the predicted box and the center of the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774f1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_detection(pred_box, gt_box, img_width=1, img_height=1):\n",
    "    \"\"\"\n",
    "    Evaluates prediction against ground truth with distance metrics.\n",
    "    \n",
    "    Args:\n",
    "        pred_box (list): [xmin, ymin, xmax, ymax]\n",
    "        gt_box (list):   [xmin, ymin, xmax, ymax]\n",
    "        img_width (int): Width of the image (for normalization)\n",
    "        img_height (int): Height of the image (for normalization)\n",
    "        \n",
    "    Returns:\n",
    "        dict: IoU, IoP, Center Distance (Pixels), Normalized Center Distance (0-1)\n",
    "    \"\"\"\n",
    "    # --- 1. IoU Calculation (Standard) ---\n",
    "    xA = max(pred_box[0], gt_box[0])\n",
    "    yA = max(pred_box[1], gt_box[1])\n",
    "    xB = min(pred_box[2], gt_box[2])\n",
    "    yB = min(pred_box[3], gt_box[3])\n",
    "    \n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    predArea = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gtArea = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "    \n",
    "    iou = interArea / float(predArea + gtArea - interArea + 1e-6)\n",
    "    iop = interArea / float(predArea + 1e-6) # Intersection over Prediction\n",
    "\n",
    "    # --- 2. Center Point Calculation ---\n",
    "    pred_cx = (pred_box[0] + pred_box[2]) / 2.0\n",
    "    pred_cy = (pred_box[1] + pred_box[3]) / 2.0\n",
    "    \n",
    "    gt_cx = (gt_box[0] + gt_box[2]) / 2.0\n",
    "    gt_cy = (gt_box[1] + gt_box[3]) / 2.0\n",
    "    \n",
    "    # --- 3. Euclidean Distance (Pixels) ---\n",
    "    # Pythagorean theorem: a^2 + b^2 = c^2\n",
    "    dist_pixels = math.sqrt((pred_cx - gt_cx)**2 + (pred_cy - gt_cy)**2)\n",
    "    \n",
    "    # --- 4. Normalized Distance (0.0 to 1.0) ---\n",
    "    # Distance relative to the image diagonal. \n",
    "    # 0.05 means the center is off by 5% of the image size.\n",
    "    # This helps compare errors across images of different resolutions.\n",
    "    img_diagonal = math.sqrt(img_width**2 + img_height**2) + 1e-6\n",
    "    norm_dist = dist_pixels / img_diagonal\n",
    "\n",
    "    return {\n",
    "        \"iou\": round(iou, 4),\n",
    "        \"iop\": round(iop, 4),\n",
    "        \"center_dist_px\": round(dist_pixels, 1),\n",
    "        \"norm_center_dist\": round(norm_dist, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad32e7",
   "metadata": {},
   "source": [
    "### Load test images and ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c038868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_path': 'data/images/test_image_152_png_jpg.rf.6336141e7564a9d7e3317f18684228bc_orig.jpg', 'groundTruth': [{'bbox_2d': [251, 504, 417, 547], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qat01f00_jpg.rf.bd6d72fb9d15b1a50aa13dc6c3ae4d92_orig.jpg', 'groundTruth': [{'bbox_2d': [346, 333, 516, 384], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jrk44a00_jpg.rf.49bde548064ee43a487d2f10ce48ff62_orig.jpg', 'groundTruth': [{'bbox_2d': [286, 511, 542, 558], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pvx38c00-page06_6_jpg.rf.c1a201f59050a76046fbf08d79c1d068_orig.jpg', 'groundTruth': [{'bbox_2d': [125, 426, 299, 469], 'label': 'signatures'}, {'bbox_2d': [377, 335, 528, 361], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_22_png_jpg.rf.08f434b8c2b4f2036d491633b08c205c_orig.jpg', 'groundTruth': [{'bbox_2d': [141, 515, 205, 543], 'label': 'signatures'}, {'bbox_2d': [158, 542, 255, 570], 'label': 'signatures'}, {'bbox_2d': [464, 564, 583, 596], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mub51a00_jpg.rf.5e443c6c89a7c80fe9fce6ea654f4295_orig.jpg', 'groundTruth': [{'bbox_2d': [331, 419, 547, 454], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_79_png_jpg.rf.039bddd38c27413f0ea712772891f643_orig.jpg', 'groundTruth': [{'bbox_2d': [180, 211, 352, 329], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bfx94e00_jpg.rf.312f555916cc292c6917ee7ce62304ff_orig.jpg', 'groundTruth': [{'bbox_2d': [517, 211, 575, 360], 'label': 'signatures'}]}, {'image_path': 'data/images/test_eut41e00_jpg.rf.ed7397480eab392c6a6630236ee112e3_orig.jpg', 'groundTruth': [{'bbox_2d': [426, 145, 500, 349], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pik10a00_jpg.rf.83e7ad398645d05935727784d1cea9e3_orig.jpg', 'groundTruth': [{'bbox_2d': [491, 381, 548, 582], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_22_png_jpg.rf.723630fb5470ebbcc76cc7964a94697f_orig.jpg', 'groundTruth': [{'bbox_2d': [449, 103, 515, 135], 'label': 'signatures'}, {'bbox_2d': [401, 73, 500, 108], 'label': 'signatures'}, {'bbox_2d': [75, 25, 196, 65], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gfz10e00_jpg.rf.bd9faebd2627c5e0636de3340c343cdf_orig.jpg', 'groundTruth': [{'bbox_2d': [223, 61, 271, 235], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zlu43d00_jpg.rf.42b17ccc22ac0cf23513d50d2edfc096_orig.jpg', 'groundTruth': [{'bbox_2d': [322, 339, 435, 375], 'label': 'signatures'}]}, {'image_path': 'data/images/test_amw93e00_jpg.rf.1952165093c5431ada193146da9b1c7c_orig.jpg', 'groundTruth': [{'bbox_2d': [396, 392, 579, 423], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qit05f00-page2_26_jpg.rf.66c0f072dd82379ebbab695fbac61b80_orig.jpg', 'groundTruth': [{'bbox_2d': [482, 128, 551, 294], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_174_png_jpg.rf.87e2cfa7d1796d4690198fd3078fd892_orig.jpg', 'groundTruth': [{'bbox_2d': [552, 287, 636, 627], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xfe44c00-page02-full-var_2_jpg.rf.c74bd9eda7a1c4e2e4de328fe4de615e_orig.jpg', 'groundTruth': [{'bbox_2d': [194, 304, 235, 481], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_43_png_jpg.rf.efc80e989532afa98e0caed0143055df_orig.jpg', 'groundTruth': [{'bbox_2d': [341, 520, 576, 554], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gzr94e00-page01_1_jpg.rf.35c37ea2a59f4bcfad6d49a09b92bd4b_orig.jpg', 'groundTruth': [{'bbox_2d': [251, 404, 322, 449], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_115_png_jpg.rf.0002dae80717fa041dba30cf3e7d5c94_orig.jpg', 'groundTruth': [{'bbox_2d': [442, 361, 555, 410], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kmw13f00_jpg.rf.5f7cd4a7e156ae72e10ba14255f61d00_orig.jpg', 'groundTruth': [{'bbox_2d': [336, 389, 497, 416], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_81_png_jpg.rf.2480158473b59c0ca1d8932d2dac8641_orig.jpg', 'groundTruth': [{'bbox_2d': [397, 560, 617, 606], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fsh23c00-page04_4_jpg.rf.fa8c218168b03530e27d12edd8a51e67_orig.jpg', 'groundTruth': [{'bbox_2d': [307, 441, 457, 467], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_158_png_jpg.rf.904e2278c42f322ad5c64da8b1c8c177_orig.jpg', 'groundTruth': [{'bbox_2d': [485, 171, 552, 323], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kcn64a00_jpg.rf.14c81cc82136c5422a905662508661b3_orig.jpg', 'groundTruth': [{'bbox_2d': [295, 504, 558, 556], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jke80e00_2_jpg.rf.39de345c0dee381ed6dc6a555edb89a8_orig.jpg', 'groundTruth': [{'bbox_2d': [257, 136, 294, 250], 'label': 'signatures'}]}, {'image_path': 'data/images/test_iny31e00_jpg.rf.5535569971bb47c20a63d366099e9935_orig.jpg', 'groundTruth': [{'bbox_2d': [89, 336, 272, 374], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bea6aa00_jpg.rf.11cf3974415da0fff453cd719fe22e0c_orig.jpg', 'groundTruth': [{'bbox_2d': [114, 474, 228, 501], 'label': 'signatures'}]}, {'image_path': 'data/images/test_rzz5aa00_jpg.rf.5df44c14258d1d0fe2451c2b7d9e23f6_orig.jpg', 'groundTruth': [{'bbox_2d': [322, 534, 410, 561], 'label': 'signatures'}]}, {'image_path': 'data/images/test_btt85f00-page2_3_jpg.rf.0a82ca1ef4f91679d21eb83f52449894_orig.jpg', 'groundTruth': [{'bbox_2d': [347, 326, 468, 371], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kci90c00_jpg.rf.fa060f7b473330842310063c52eb3401_orig.jpg', 'groundTruth': [{'bbox_2d': [427, 61, 503, 271], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jiy01a00-page02_2_jpg.rf.fcba33ac77f3c971c9661e4c3e5bde57_orig.jpg', 'groundTruth': [{'bbox_2d': [152, 89, 239, 287], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_171_png_jpg.rf.0ee4bce9a8b510c3ffec3821754fb8c6_orig.jpg', 'groundTruth': [{'bbox_2d': [86, 83, 144, 264], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wav95e00-page03_3_jpg.rf.3606aa1819b7e00fac800fbe1394c959_orig.jpg', 'groundTruth': [{'bbox_2d': [336, 286, 555, 316], 'label': 'signatures'}, {'bbox_2d': [74, 366, 206, 392], 'label': 'signatures'}, {'bbox_2d': [76, 414, 223, 444], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xjx9aa00-first_jpg.rf.cc4b0495b4cb9561be64c3b8f8d79c23_orig.jpg', 'groundTruth': [{'bbox_2d': [3, 440, 286, 500], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_112_png_jpg.rf.59ee3340506295ebf9fbd7ec86d491c5_orig.jpg', 'groundTruth': [{'bbox_2d': [167, 230, 247, 458], 'label': 'signatures'}, {'bbox_2d': [303, 279, 336, 420], 'label': 'signatures'}, {'bbox_2d': [384, 203, 438, 435], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zqc25f00_1_jpg.rf.0f3c682ee6a33430cf607a42316d3a1b_orig.jpg', 'groundTruth': [{'bbox_2d': [246, 409, 281, 500], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_170_png_jpg.rf.98cab588a87897bca132a412400dd4a1_orig.jpg', 'groundTruth': [{'bbox_2d': [60, 196, 232, 273], 'label': 'signatures'}]}, {'image_path': 'data/images/test_cji44a00_jpg.rf.746ecadc485a65ebe3e2eedd2f05419a_orig.jpg', 'groundTruth': [{'bbox_2d': [222, 193, 275, 312], 'label': 'signatures'}, {'bbox_2d': [249, 384, 306, 533], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jrk44a00_jpg.rf.e52fbd4e6f48e5eee1ffccb9f2df038f_orig.jpg', 'groundTruth': [{'bbox_2d': [495, 89, 558, 347], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dch31f00_jpg.rf.58d0f3d1decff9cae7e577a046fec9a4_orig.jpg', 'groundTruth': [{'bbox_2d': [368, 352, 515, 377], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wry97e00_jpg.rf.999b2e66f5e6e5c7894576666876387d_orig.jpg', 'groundTruth': [{'bbox_2d': [65, 397, 146, 470], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_116_png_jpg.rf.62544773c94725706e3db218c3f17de7_orig.jpg', 'groundTruth': [{'bbox_2d': [2, 154, 290, 266], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_176_png_jpg.rf.d85abd47a2f0939acdff9b20d650f3ae_orig.jpg', 'groundTruth': [{'bbox_2d': [342, 469, 375, 531], 'label': 'signatures'}, {'bbox_2d': [373, 497, 396, 526], 'label': 'signatures'}, {'bbox_2d': [361, 331, 388, 361], 'label': 'signatures'}, {'bbox_2d': [352, 181, 380, 231], 'label': 'signatures'}, {'bbox_2d': [376, 64, 406, 135], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_41_png_jpg.rf.915d23c370264c9471bc93da6a0e6676_orig.jpg', 'groundTruth': [{'bbox_2d': [80, 150, 339, 233], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_70_png_jpg.rf.4637922c81e04ab5035bcd981065dd2a_orig.jpg', 'groundTruth': [{'bbox_2d': [210, 337, 462, 468], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_37_png_jpg.rf.4492aaf14c811d90335fbc7408a34a81_orig.jpg', 'groundTruth': [{'bbox_2d': [365, 463, 576, 537], 'label': 'signatures'}, {'bbox_2d': [27, 444, 187, 517], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wcq76d00_jpg.rf.f3af6d294a984e198097b734c559e46f_orig.jpg', 'groundTruth': [{'bbox_2d': [301, 511, 569, 566], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wau30a00-page9_9_jpg.rf.cb4ea14b627ac8aeabf89502e764b11d_orig.jpg', 'groundTruth': [{'bbox_2d': [195, 79, 299, 100], 'label': 'signatures'}, {'bbox_2d': [406, 78, 558, 108], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nrg54f00-page02_1_jpg.rf.69ceffc963d20bfedaeb4ff8ccd5a188_orig.jpg', 'groundTruth': [{'bbox_2d': [210, 269, 265, 426], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fzx20e00-page02_2_jpg.rf.c9237466b19dbe75cfb8b7b1e2d74683_orig.jpg', 'groundTruth': [{'bbox_2d': [123, 457, 278, 487], 'label': 'signatures'}, {'bbox_2d': [313, 313, 423, 338], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_67_png_jpg.rf.a141646b4809e3f8bcbbc4724487ff0a_orig.jpg', 'groundTruth': [{'bbox_2d': [78, 145, 194, 214], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_161_png_jpg.rf.1bb45c8d3ed98a8a433471b444f0ec37_orig.jpg', 'groundTruth': [{'bbox_2d': [407, 513, 608, 590], 'label': 'signatures'}, {'bbox_2d': [5, 528, 203, 596], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zqc25f00_1_jpg.rf.5a0b33af2ff6efa22ebcf62ed6c251cf_orig.jpg', 'groundTruth': [{'bbox_2d': [123, 262, 218, 310], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wej25f00_jpg.rf.ea6bfd33c20b4a35819652949bb5b930_orig.jpg', 'groundTruth': [{'bbox_2d': [342, 322, 440, 353], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_25_png_jpg.rf.374987ccaf16fe55f8e64c2bd43c3241_orig.jpg', 'groundTruth': [{'bbox_2d': [54, 179, 153, 493], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_10_png_jpg.rf.2107edd076605a2f762298d01f2ee223_orig.jpg', 'groundTruth': [{'bbox_2d': [428, 169, 468, 232], 'label': 'signatures'}]}, {'image_path': 'data/images/test_alk3aa00_jpg.rf.708722a2f39b6220603e4a454cb257b8_orig.jpg', 'groundTruth': [{'bbox_2d': [429, 119, 468, 268], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_29_jpg.rf.1f0e7d2d3d255862e9f3b6256cce285b_orig.jpg', 'groundTruth': [{'bbox_2d': [391, 259, 583, 335], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ouq21c00_jpg.rf.57a651540d7c3c6b41b20620e99f34c9_orig.jpg', 'groundTruth': [{'bbox_2d': [287, 413, 386, 446], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mlr04f00_jpg.rf.64a74c60903e31b51fafd4d8557fbf92_orig.jpg', 'groundTruth': [{'bbox_2d': [336, 487, 467, 522], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_120_png_jpg.rf.926daf134978ac9c64c7f84a267d3362_orig.jpg', 'groundTruth': [{'bbox_2d': [63, 482, 171, 514], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nul00a00_jpg.rf.ff7f6f49f252adefa95c0f6bc7316794_orig.jpg', 'groundTruth': [{'bbox_2d': [519, 28, 614, 241], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_10_png_jpg.rf.9ecc9f5ccc27ea53054413545137a793_orig.jpg', 'groundTruth': [{'bbox_2d': [435, 410, 494, 440], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fzx20e00-page02_2_jpg.rf.eaf2cb71b1939612b691491bee29a541_orig.jpg', 'groundTruth': [{'bbox_2d': [342, 138, 499, 185], 'label': 'signatures'}, {'bbox_2d': [210, 305, 322, 342], 'label': 'signatures'}]}, {'image_path': 'data/images/test_syi15f00_jpg.rf.441871dd255469167cc1907a990b63bd_orig.jpg', 'groundTruth': [{'bbox_2d': [395, 375, 505, 415], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nht43d00-page02_2_jpg.rf.df5eeda25e0213bec1e12a8a194b8c3e_orig.jpg', 'groundTruth': [{'bbox_2d': [310, 148, 493, 192], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bkz54f00_1_jpg.rf.c659bf2322abceb08b3c3eeb463cb7a4_orig.jpg', 'groundTruth': [{'bbox_2d': [373, 113, 429, 282], 'label': 'signatures'}]}, {'image_path': 'data/images/test_erk44a00_1_jpg.rf.c0f17ec585b507f8977d64f283dc1fdf_orig.jpg', 'groundTruth': [{'bbox_2d': [336, 501, 580, 544], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jaw63f00-var-full_2_jpg.rf.6f19d39713667f0e1fa1921b191dc5da_orig.jpg', 'groundTruth': [{'bbox_2d': [334, 529, 414, 553], 'label': 'signatures'}]}, {'image_path': 'data/images/test_men43c00_jpg.rf.daa84cb1cff905fc1519633775f0e676_orig.jpg', 'groundTruth': [{'bbox_2d': [334, 408, 446, 426], 'label': 'signatures'}]}, {'image_path': 'data/images/test_vcv85f00_jpg.rf.a15cd52cbbc14231fd60cea0c8a525f5_orig.jpg', 'groundTruth': [{'bbox_2d': [317, 404, 476, 446], 'label': 'signatures'}, {'bbox_2d': [505, 317, 606, 357], 'label': 'signatures'}]}, {'image_path': 'data/images/test_vaw13f00_jpg.rf.e428ecff155d1507c1a85d0ddde59bb9_orig.jpg', 'groundTruth': [{'bbox_2d': [319, 484, 457, 515], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_114_png_jpg.rf.eb0e123e88cb16dfbaa1bec26fe67bbb_orig.jpg', 'groundTruth': [{'bbox_2d': [113, 445, 177, 554], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_121_png_jpg.rf.5f8e72b661b75ce3cab5dcb4ac2b4961_orig.jpg', 'groundTruth': [{'bbox_2d': [536, 44, 638, 100], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fwe69c00_jpg.rf.3830ea85f46b61a93aa7bb26e49b1ef1_orig.jpg', 'groundTruth': [{'bbox_2d': [247, 335, 307, 491], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_59_png_jpg.rf.6418f9896ab3e8388d14ca7cd8031e7f_orig.jpg', 'groundTruth': [{'bbox_2d': [451, 476, 539, 512], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pfv39d00_jpg.rf.aad0bb15d3ae56f4ec53561215567e0c_orig.jpg', 'groundTruth': [{'bbox_2d': [353, 484, 541, 506], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xfe44c00-page02-full-var_2_jpg.rf.9c3c26e6752bdd8b4d11a190bf815bf2_orig.jpg', 'groundTruth': [{'bbox_2d': [150, 202, 326, 240], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wud23f00_jpg.rf.e33766988d8522303bf49455a3c73c08_orig.jpg', 'groundTruth': [{'bbox_2d': [85, 499, 228, 549], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xmw13f00_jpg.rf.35dfb872b4d28c60f2d53bb9ac883eb7_orig.jpg', 'groundTruth': [{'bbox_2d': [117, 203, 301, 239], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pjw13f00_jpg.rf.c87bc2d6b3c132d1dccc706c63d8b78f_orig.jpg', 'groundTruth': [{'bbox_2d': [385, 126, 540, 157], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_126_png_jpg.rf.0aa87a7f7697380f87eec24c197a3f7f_orig.jpg', 'groundTruth': [{'bbox_2d': [339, 524, 508, 611], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_146_png_jpg.rf.5e25a0ae84c27a6ec5818275f8bc73a6_orig.jpg', 'groundTruth': [{'bbox_2d': [295, 507, 603, 584], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_45_png_jpg.rf.968d4a2cb0b8d87369b2adb1e4c76a06_orig.jpg', 'groundTruth': [{'bbox_2d': [224, 502, 405, 548], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_168_png_jpg.rf.a8fb7f67b7a1d8a98700cc29773bcbb7_orig.jpg', 'groundTruth': [{'bbox_2d': [197, 535, 300, 597], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mtq30d00_4_jpg.rf.713e9ccdc44caab43d574d9313bb1428_orig.jpg', 'groundTruth': [{'bbox_2d': [109, 299, 307, 337], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xqw35e00_jpg.rf.7698e87d6562c8038ff33ffc3fea8699_orig.jpg', 'groundTruth': [{'bbox_2d': [375, 197, 435, 364], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wzt35f00_jpg.rf.757cd551ba6678a5d094dfcc508ff9d9_orig.jpg', 'groundTruth': [{'bbox_2d': [351, 341, 413, 617], 'label': 'signatures'}, {'bbox_2d': [333, 162, 387, 327], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bfx94e00_jpg.rf.4791a2c77040e4eae994fc52ecd1b70d_orig.jpg', 'groundTruth': [{'bbox_2d': [297, 517, 443, 564], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kfj00a00_jpg.rf.1d7ad3b204b91956c4d6b03cb6fd9338_orig.jpg', 'groundTruth': [{'bbox_2d': [292, 510, 551, 627], 'label': 'signatures'}]}, {'image_path': 'data/images/test_aji32e00-page02_2_jpg.rf.2b07ffec9280b53b574fa9d7fef80681_orig.jpg', 'groundTruth': [{'bbox_2d': [308, 422, 559, 531], 'label': 'signatures'}]}, {'image_path': 'data/images/test_djz54f00_jpg.rf.54f9c76412cc5cb5cfa1586d944c1849_orig.jpg', 'groundTruth': [{'bbox_2d': [144, 181, 283, 228], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_80_png_jpg.rf.7bdb9f7fa13715faa4ad0a3e294341ae_orig.jpg', 'groundTruth': [{'bbox_2d': [82, 374, 246, 446], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ghz25e00_jpg.rf.7ee9753ae292943951ced3e69747fa07_orig.jpg', 'groundTruth': [{'bbox_2d': [137, 459, 350, 547], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_55_png_jpg.rf.4729bdcbb329e22a2f5cf4092557360e_orig.jpg', 'groundTruth': [{'bbox_2d': [269, 13, 314, 178], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_33_png_jpg.rf.7c408eba9ff8926c637a55dfe3bcbf66_orig.jpg', 'groundTruth': [{'bbox_2d': [189, 130, 346, 240], 'label': 'signatures'}]}, {'image_path': 'data/images/test_diy01a00-page02_2_jpg.rf.08f85dbffce5309bf14a8e02bbea7ea0_orig.jpg', 'groundTruth': [{'bbox_2d': [158, 215, 312, 287], 'label': 'signatures'}]}, {'image_path': 'data/images/test_duz52d00-page02-var_3_jpg.rf.ba637c7a2fdcd990c0c1f843200b1d96_orig.jpg', 'groundTruth': [{'bbox_2d': [456, 352, 506, 402], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_58_png_jpg.rf.753345ee524a9bd30dce01e686d13549_orig.jpg', 'groundTruth': [{'bbox_2d': [513, 274, 543, 395], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fny38c00-page05_5_jpg.rf.ac33a762dae88be01127a1d08b85a382_orig.jpg', 'groundTruth': [{'bbox_2d': [387, 192, 562, 236], 'label': 'signatures'}, {'bbox_2d': [559, 223, 597, 244], 'label': 'signatures'}, {'bbox_2d': [349, 86, 595, 149], 'label': 'signatures'}, {'bbox_2d': [346, 130, 575, 183], 'label': 'signatures'}, {'bbox_2d': [445, 256, 573, 293], 'label': 'signatures'}]}, {'image_path': 'data/images/test_cgy54f00_1_jpg.rf.281e9627f64881f6f4026969832980f0_orig.jpg', 'groundTruth': [{'bbox_2d': [391, 375, 489, 417], 'label': 'signatures'}]}, {'image_path': 'data/images/test_oan00d00_jpg.rf.da484d45d9343039cbd4e98ce0f2babd_orig.jpg', 'groundTruth': [{'bbox_2d': [189, 178, 357, 225], 'label': 'signatures'}]}, {'image_path': 'data/images/test_rji44a00_jpg.rf.f8f440caef2fb76d61871f153e6dfc0a_orig.jpg', 'groundTruth': [{'bbox_2d': [388, 283, 575, 321], 'label': 'signatures'}, {'bbox_2d': [211, 289, 350, 315], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_142_png_jpg.rf.260dde6ddc35559cf5620fee3fac6947_orig.jpg', 'groundTruth': [{'bbox_2d': [190, 399, 267, 596], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qbh54c00-page02_2_jpg.rf.691d0812d0192c1423a746b5da2cad04_orig.jpg', 'groundTruth': [{'bbox_2d': [302, 218, 429, 244], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_26_png_jpg.rf.d78d81efbb2a70fb8e95266290bb9d21_orig.jpg', 'groundTruth': [{'bbox_2d': [141, 386, 303, 531], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gfg5aa00_jpg.rf.7f3cff9680ca10ed7067cb767f2f08b6_orig.jpg', 'groundTruth': [{'bbox_2d': [189, 393, 276, 456], 'label': 'signatures'}, {'bbox_2d': [413, 390, 511, 412], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_77_png_jpg.rf.b425532831efcb74d8eef1f749dc59dc_orig.jpg', 'groundTruth': [{'bbox_2d': [29, 455, 196, 510], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_152_png_jpg.rf.05c065b0dea8edd5e4843dcdecb77c47_orig.jpg', 'groundTruth': [{'bbox_2d': [227, 91, 394, 140], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_143_png_jpg.rf.47099882db4439efa2b94094f0f70c1b_orig.jpg', 'groundTruth': [{'bbox_2d': [45, 93, 256, 145], 'label': 'signatures'}]}, {'image_path': 'data/images/test_osv63f00_2_jpg.rf.41bf17e504a9893642741225b2db8e61_orig.jpg', 'groundTruth': [{'bbox_2d': [376, 523, 451, 552], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_120_png_jpg.rf.5d5667e741c50cf87ba6d40c7c6ae178_orig.jpg', 'groundTruth': [{'bbox_2d': [476, 469, 512, 578], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wat01f00_jpg.rf.e51347d9b0783f451160527f8e4d3fda_orig.jpg', 'groundTruth': [{'bbox_2d': [362, 335, 494, 368], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pvx38c00-page06_6_jpg.rf.820f4caeb7ecbd422495362bbcd0d94e_orig.jpg', 'groundTruth': [{'bbox_2d': [418, 340, 467, 515], 'label': 'signatures'}, {'bbox_2d': [326, 113, 357, 264], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ehi41f00_jpg.rf.cb4d60a05f7d9ebe8ca70a4cd3d6127f_orig.jpg', 'groundTruth': [{'bbox_2d': [317, 464, 443, 494], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_74_png_jpg.rf.7999fc401da367dddc928f98a71b27fd_orig.jpg', 'groundTruth': [{'bbox_2d': [489, 55, 539, 175], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wau30a00-page9_10_jpg.rf.6d533900e8f25110b4b2f333a24ee35d_orig.jpg', 'groundTruth': [{'bbox_2d': [124, 126, 320, 151], 'label': 'signatures'}, {'bbox_2d': [362, 124, 620, 155], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_85_png_jpg.rf.fee9ade0445ab24dd1e98965b5f80996_orig.jpg', 'groundTruth': [{'bbox_2d': [354, 535, 584, 562], 'label': 'signatures'}]}, {'image_path': 'data/images/test_hfn24f00_jpg.rf.5f2f0bf959100d590bc77840c5b33a81_orig.jpg', 'groundTruth': [{'bbox_2d': [297, 486, 452, 521], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_197_png_jpg.rf.db7fd6b681ee0829569d1534b8a90adf_orig.jpg', 'groundTruth': [{'bbox_2d': [490, 464, 639, 580], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_101_png_jpg.rf.6099ffc510bd89e9521ecfb867f06a01_orig.jpg', 'groundTruth': [{'bbox_2d': [96, 13, 348, 102], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sfp41a00-page5_2_jpg.rf.bd340480b71f8340ee1f8a21c241868b_orig.jpg', 'groundTruth': [{'bbox_2d': [147, 534, 274, 560], 'label': 'signatures'}, {'bbox_2d': [371, 532, 489, 563], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_125_png_jpg.rf.ed26f585532d5026fd6160b086fa4120_orig.jpg', 'groundTruth': [{'bbox_2d': [232, 448, 388, 534], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bfk68c00-page03_3_jpg.rf.050a0516df8f6e744753c2ed22270e92_orig.jpg', 'groundTruth': [{'bbox_2d': [216, 389, 271, 562], 'label': 'signatures'}]}, {'image_path': 'data/images/test_cxk72e00-page03_3_jpg.rf.2b3b5db67f31553dd7d48ce9c3fe479b_orig.jpg', 'groundTruth': [{'bbox_2d': [398, 345, 488, 365], 'label': 'signatures'}, {'bbox_2d': [78, 408, 289, 452], 'label': 'signatures'}]}, {'image_path': 'data/images/test_hst85f00_jpg.rf.5d44108bb48b56ada540be01e444bc20_orig.jpg', 'groundTruth': [{'bbox_2d': [346, 312, 479, 342], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_132_png_jpg.rf.f80e60058db08028e62df159d771a7f2_orig.jpg', 'groundTruth': [{'bbox_2d': [217, 460, 527, 548], 'label': 'signatures'}]}, {'image_path': 'data/images/test_arz92e00_jpg.rf.d032a45166eda3a7b6ca41c47bde7d69_orig.jpg', 'groundTruth': [{'bbox_2d': [306, 395, 462, 428], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pvx38c00-page06_6_jpg.rf.a305f6159151b20bd5f683e71ff72ba5_orig.jpg', 'groundTruth': [{'bbox_2d': [452, 150, 495, 176], 'label': 'signatures'}, {'bbox_2d': [338, 171, 518, 211], 'label': 'signatures'}, {'bbox_2d': [96, 278, 281, 311], 'label': 'signatures'}]}, {'image_path': 'data/images/test_juo75f00_1_jpg.rf.f10e229cdb594f0f3e13e30f9777b533_orig.jpg', 'groundTruth': [{'bbox_2d': [340, 272, 431, 300], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_103_png_jpg.rf.00b2dfef4eec24911863ffa7b0e5a4ee_orig.jpg', 'groundTruth': [{'bbox_2d': [350, 359, 444, 573], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_66_png_jpg.rf.58a5cb6772a988c2777f4ad2d2f9190f_orig.jpg', 'groundTruth': [{'bbox_2d': [78, 458, 225, 520], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_153_png_jpg.rf.8503a76269c0383eb66cd72540e1f068_orig.jpg', 'groundTruth': [{'bbox_2d': [316, 396, 498, 424], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_17_jpg.rf.187c45a04f952ab419f1a77005dc40f9_orig.jpg', 'groundTruth': [{'bbox_2d': [44, 294, 347, 372], 'label': 'signatures'}]}, {'image_path': 'data/images/test_cxk72e00-page03_3_jpg.rf.d6ffc3aa503920892bd7e4385ea18fa1_orig.jpg', 'groundTruth': [{'bbox_2d': [147, 277, 241, 308], 'label': 'signatures'}, {'bbox_2d': [357, 183, 545, 238], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_119_png_jpg.rf.66829481187070604355337cc31599ad_orig.jpg', 'groundTruth': [{'bbox_2d': [89, 487, 207, 532], 'label': 'signatures'}]}, {'image_path': 'data/images/test_rsj41f00-page02_2_jpg.rf.5dd721520e39f3be496fbbaef341511b_orig.jpg', 'groundTruth': [{'bbox_2d': [326, 316, 499, 345], 'label': 'signatures'}]}, {'image_path': 'data/images/test_syi15f00_jpg.rf.4e8bdc265773aa9f7b22fce13f7a2353_orig.jpg', 'groundTruth': [{'bbox_2d': [228, 395, 276, 508], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wme03e00_jpg.rf.f5014b89d664e9ecbe4d7d8f99bccd76_orig.jpg', 'groundTruth': [{'bbox_2d': [301, 346, 459, 379], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mos87c00-page02_2_jpg.rf.897c08ad8a195fe87bc389a4f4487929_orig.jpg', 'groundTruth': [{'bbox_2d': [323, 252, 498, 308], 'label': 'signatures'}, {'bbox_2d': [337, 235, 503, 251], 'label': 'signatures'}, {'bbox_2d': [295, 309, 534, 361], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sks41a00_jpg.rf.9b3f36533d797e5caa6cbadc35cf9e6e_orig.jpg', 'groundTruth': [{'bbox_2d': [329, 461, 524, 494], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zjy03e00-page02_2_jpg.rf.57caf924bceedb389ad5669dba647296_orig.jpg', 'groundTruth': [{'bbox_2d': [324, 226, 468, 258], 'label': 'signatures'}, {'bbox_2d': [98, 368, 226, 391], 'label': 'signatures'}]}, {'image_path': 'data/images/test_tyo25f00_jpg.rf.e0bb9a353b4b1904520a7f1a3495e4a4_orig.jpg', 'groundTruth': [{'bbox_2d': [341, 283, 545, 322], 'label': 'signatures'}]}, {'image_path': 'data/images/test_oan00d00_jpg.rf.1efbfa1a864ef1d24bf5ef1d2d0ed226_orig.jpg', 'groundTruth': [{'bbox_2d': [282, 420, 449, 466], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nyk41e00_jpg.rf.5f735228c86619e87d971cd33a589f39_orig.jpg', 'groundTruth': [{'bbox_2d': [81, 423, 242, 461], 'label': 'signatures'}]}, {'image_path': 'data/images/test_yme01e00-page01_1_jpg.rf.34869c92f02475e90ef7df94c04024b6_orig.jpg', 'groundTruth': [{'bbox_2d': [302, 319, 472, 348], 'label': 'signatures'}]}, {'image_path': 'data/images/test_khz25e00_jpg.rf.cb43985e0f23ef54733dd62845042dca_orig.jpg', 'groundTruth': [{'bbox_2d': [124, 71, 207, 294], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_38_png_jpg.rf.3eb2103b7015791280c2a4e8e750e6bb_orig.jpg', 'groundTruth': [{'bbox_2d': [198, 55, 241, 173], 'label': 'signatures'}, {'bbox_2d': [263, 195, 287, 238], 'label': 'signatures'}, {'bbox_2d': [518, 37, 564, 136], 'label': 'signatures'}, {'bbox_2d': [587, 157, 615, 209], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_175_png_jpg.rf.c8db86aa191426cf63aa29dbb3acdc09_orig.jpg', 'groundTruth': [{'bbox_2d': [369, 525, 586, 575], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qit05f00-page2_36_jpg.rf.5f18b0bd94a32343c0ba332ce45205d1_orig.jpg', 'groundTruth': [{'bbox_2d': [315, 296, 497, 355], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_160_png_jpg.rf.155756d6829ccf98535708a7d0b870b0_orig.jpg', 'groundTruth': [{'bbox_2d': [113, 170, 199, 334], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sfw98c00_jpg.rf.7985d1b95a748bfb00b4eae63a31b181_orig.jpg', 'groundTruth': [{'bbox_2d': [298, 360, 460, 427], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dqn43c00_jpg.rf.e504cc92b482eb15c5bd40e6556f5cc7_orig.jpg', 'groundTruth': [{'bbox_2d': [433, 208, 549, 237], 'label': 'signatures'}]}, {'image_path': 'data/images/test_avd23f00-first_1_jpg.rf.22905f13dcece0e2eb24a02347f3f8d7_orig.jpg', 'groundTruth': [{'bbox_2d': [272, 366, 454, 407], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_184_png_jpg.rf.eac2fec28539a3d8b06d5c1bb0869165_orig.jpg', 'groundTruth': [{'bbox_2d': [156, 58, 211, 246], 'label': 'signatures'}, {'bbox_2d': [145, 257, 215, 402], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_128_png_jpg.rf.9f6f8f3726072fd6a3eb03a61c66c2b4_orig.jpg', 'groundTruth': [{'bbox_2d': [166, 132, 283, 195], 'label': 'signatures'}, {'bbox_2d': [384, 111, 612, 204], 'label': 'signatures'}]}, {'image_path': 'data/images/test_jke80e00_2_jpg.rf.15a02d155b2a194a6578d02cac5f0d36_orig.jpg', 'groundTruth': [{'bbox_2d': [350, 385, 382, 498], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_70_png_jpg.rf.0c014d1f7fa2be5527ee856dd2bbfb55_orig.jpg', 'groundTruth': [{'bbox_2d': [355, 209, 450, 446], 'label': 'signatures'}]}, {'image_path': 'data/images/test_aam09c00_jpg.rf.be02fbea5e3f4269a2419952cff0c8b2_orig.jpg', 'groundTruth': [{'bbox_2d': [304, 397, 584, 447], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sik79d00_jpg.rf.998bb80ae83e0bab9d7d8710ba233bd7_orig.jpg', 'groundTruth': [{'bbox_2d': [62, 301, 105, 453], 'label': 'signatures'}, {'bbox_2d': [35, 315, 76, 488], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dkn80f00_jpg.rf.c6928feaba11c927be73b84912eaa9d7_orig.jpg', 'groundTruth': [{'bbox_2d': [317, 334, 499, 370], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fpi68d00_jpg.rf.e4cfe6089e49950a390f4658ecee0dd0_orig.jpg', 'groundTruth': [{'bbox_2d': [297, 345, 491, 375], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ghz25e00_jpg.rf.25344e1ed856d0f70db27bc023ffa497_orig.jpg', 'groundTruth': [{'bbox_2d': [65, 427, 279, 518], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_46_png_jpg.rf.e82d7cf5a3e1be8f62e288d51101b1c8_orig.jpg', 'groundTruth': [{'bbox_2d': [527, 457, 607, 557], 'label': 'signatures'}, {'bbox_2d': [506, 227, 600, 366], 'label': 'signatures'}, {'bbox_2d': [521, 75, 596, 179], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zmw13f00_jpg.rf.df84d6155f3d52b83a200dc4a06dc373_orig.jpg', 'groundTruth': [{'bbox_2d': [200, 325, 250, 558], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nnj41f00_jpg.rf.2e7bf0011f74d6626b578ae8405ca2a3_orig.jpg', 'groundTruth': [{'bbox_2d': [345, 382, 498, 412], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_194_png_jpg.rf.df62e6999256fb2302fa5bd7ba0b18e1_orig.jpg', 'groundTruth': [{'bbox_2d': [308, 503, 400, 541], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_134_png_jpg.rf.30ffb3de24a79b812e4823a19a2fffbc_orig.jpg', 'groundTruth': [{'bbox_2d': [441, 321, 485, 589], 'label': 'signatures'}]}, {'image_path': 'data/images/test_yaq00e00_jpg.rf.b78f90604695c5a5ccc065c498eb7423_orig.jpg', 'groundTruth': [{'bbox_2d': [289, 361, 442, 411], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gmk15f00_jpg.rf.98cfdbd113300d0ec81569ae38664908_orig.jpg', 'groundTruth': [{'bbox_2d': [391, 442, 511, 478], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sik79d00_jpg.rf.ac9ae2ffb10ac82a02cdb21adadd9a3b_orig.jpg', 'groundTruth': [{'bbox_2d': [138, 80, 291, 130], 'label': 'signatures'}, {'bbox_2d': [96, 60, 270, 109], 'label': 'signatures'}]}, {'image_path': 'data/images/test_khz25e00_jpg.rf.18c08f49d5d69fcfbb498195388c9d14_orig.jpg', 'groundTruth': [{'bbox_2d': [464, 324, 515, 542], 'label': 'signatures'}]}, {'image_path': 'data/images/test_nzy64f00-var_1_jpg.rf.d4de0a41867bd25eb4a378b9161ea45e_orig.jpg', 'groundTruth': [{'bbox_2d': [441, 160, 514, 321], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sma35f00_jpg.rf.375b78dcdffebf3c1df37be8bc542a54_orig.jpg', 'groundTruth': [{'bbox_2d': [356, 435, 488, 482], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_100_png_jpg.rf.2b7b1c1a60605ce52dcf3942590a5e76_orig.jpg', 'groundTruth': [{'bbox_2d': [362, 390, 601, 448], 'label': 'signatures'}, {'bbox_2d': [73, 386, 311, 429], 'label': 'signatures'}, {'bbox_2d': [120, 311, 298, 361], 'label': 'signatures'}, {'bbox_2d': [361, 298, 560, 354], 'label': 'signatures'}, {'bbox_2d': [374, 231, 580, 279], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dvr41a00_jpg.rf.cc4a5c4a7224d4e8ddb9729b8055dff0_orig.jpg', 'groundTruth': [{'bbox_2d': [316, 390, 483, 430], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mge98e00_jpg.rf.756e348aaa6414f5477ba252d43d3d07_orig.jpg', 'groundTruth': [{'bbox_2d': [141, 368, 169, 527], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gDpRwC_png_jpg.rf.dae7be686913c7885718640f7fcacf34_orig.jpg', 'groundTruth': [{'bbox_2d': [58, 441, 104, 480], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_12_png_jpg.rf.73faa62377c651b4eb3be0f0f439d00e_orig.jpg', 'groundTruth': [{'bbox_2d': [71, 389, 265, 476], 'label': 'signatures'}]}, {'image_path': 'data/images/test_btu54a00_jpg.rf.43b00ee0ccf7e577f3be975c983bfb93_orig.jpg', 'groundTruth': [{'bbox_2d': [400, 312, 504, 346], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zqr09c00_jpg.rf.b7c8c650ba3e10b2579162a5a7fd9754_orig.jpg', 'groundTruth': [{'bbox_2d': [81, 514, 200, 550], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_11_png_jpg.rf.733e539047b02be17ce33142d4a5c2cb_orig.jpg', 'groundTruth': [{'bbox_2d': [117, 123, 209, 224], 'label': 'signatures'}]}, {'image_path': 'data/images/test_fgx54f00_1_jpg.rf.6d8039f6d5ae6cb003d43d7ff19630fb_orig.jpg', 'groundTruth': [{'bbox_2d': [348, 129, 401, 241], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pek94c00_2_jpg.rf.aa96c368599989c867e7906786056dd1_orig.jpg', 'groundTruth': [{'bbox_2d': [287, 421, 457, 459], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kcn64a00_jpg.rf.d261ef4e4bb5140bb6f876bec87bb22d_orig.jpg', 'groundTruth': [{'bbox_2d': [85, 305, 152, 570], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gfg5aa00_jpg.rf.73fb6060ac3f140ef2713bba9f1bf320_orig.jpg', 'groundTruth': [{'bbox_2d': [358, 172, 448, 240], 'label': 'signatures'}, {'bbox_2d': [125, 231, 224, 259], 'label': 'signatures'}]}, {'image_path': 'data/images/test_std20e00-page01_1_jpg.rf.77c233a0c0a57e44f32307b67d9148cc_orig.jpg', 'groundTruth': [{'bbox_2d': [296, 338, 432, 383], 'label': 'signatures'}]}, {'image_path': 'data/images/test_rgj46d00_jpg.rf.7fbe53a5681e0347204d34e321e30d8e_orig.jpg', 'groundTruth': [{'bbox_2d': [454, 405, 510, 421], 'label': 'signatures'}, {'bbox_2d': [35, 508, 178, 553], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sik79d00_jpg.rf.657dabbd2fed143af1b8a07303d179b3_orig.jpg', 'groundTruth': [{'bbox_2d': [323, 535, 466, 562], 'label': 'signatures'}, {'bbox_2d': [335, 564, 509, 586], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_7_jpg.rf.530ddd39e38edc758db0d0d2257637bf_orig.jpg', 'groundTruth': [{'bbox_2d': [392, 427, 460, 530], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wzt35f00_jpg.rf.f4c1e8d4f47eb348a76e243762e55b62_orig.jpg', 'groundTruth': [{'bbox_2d': [23, 360, 297, 385], 'label': 'signatures'}, {'bbox_2d': [315, 358, 477, 391], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dsj50c00-page04_4_jpg.rf.b889e6f0ebeef20b43aadce36b7d0162_orig.jpg', 'groundTruth': [{'bbox_2d': [183, 173, 336, 213], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qat01f00_jpg.rf.29bf200abfac8aa7f276b9e1a7936d63_orig.jpg', 'groundTruth': [{'bbox_2d': [363, 337, 495, 370], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pzm00d00_jpg.rf.4818c75c5d1b9308fa4b43bb73040ea2_orig.jpg', 'groundTruth': [{'bbox_2d': [349, 388, 489, 434], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_153_png_jpg.rf.2efdf9ceb36eb2521c329743345b6577_orig.jpg', 'groundTruth': [{'bbox_2d': [390, 144, 421, 326], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_116_png_jpg.rf.d8979a4b6bc54dbadad006e4dec72d60_orig.jpg', 'groundTruth': [{'bbox_2d': [329, 408, 611, 484], 'label': 'signatures'}]}, {'image_path': 'data/images/test_eoc33a00-page02_2_jpg.rf.d1469b84037507db6b3c37f9a90ddc5d_orig.jpg', 'groundTruth': [{'bbox_2d': [391, 278, 573, 305], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gwo3aa00_jpg.rf.f7ba57159adedc2c618c7c53f85c411b_orig.jpg', 'groundTruth': [{'bbox_2d': [298, 326, 331, 458], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qit05f00-page2_24_jpg.rf.364e136ca2641003c2828503f665f1b3_orig.jpg', 'groundTruth': [{'bbox_2d': [232, 112, 298, 319], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_171_png_jpg.rf.3632c025d9a90dcaf83552bbe40ae952_orig.jpg', 'groundTruth': [{'bbox_2d': [66, 489, 244, 529], 'label': 'signatures'}]}, {'image_path': 'data/images/test_juo75f00_36_jpg.rf.7b39c707e111e9a5f4c22b701ed3e223_orig.jpg', 'groundTruth': [{'bbox_2d': [283, 262, 354, 292], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_35_jpg.rf.ef0b4160130a4b43002aa90098a92094_orig.jpg', 'groundTruth': [{'bbox_2d': [13, 14, 64, 77], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mnq44a00_jpg.rf.a289403f2bb8f6ef59b5f01a00ea2384_orig.jpg', 'groundTruth': [{'bbox_2d': [140, 114, 205, 134], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qbh54c00-page02_2_jpg.rf.0be2587eb77a8c3dfe6a639686c44344_orig.jpg', 'groundTruth': [{'bbox_2d': [303, 218, 430, 244], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pik10a00_jpg.rf.33965460de4673489e90b4bf8320e2de_orig.jpg', 'groundTruth': [{'bbox_2d': [507, 377, 560, 577], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ivw54f00_1_jpg.rf.5357b53ac155ce2a6ec0de2eadd39238_orig.jpg', 'groundTruth': [{'bbox_2d': [261, 323, 306, 443], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_77_png_jpg.rf.4ade57720bf1c04779f3e426cc979c8c_orig.jpg', 'groundTruth': [{'bbox_2d': [26, 457, 194, 516], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pji44a00_jpg.rf.ffa2a51a74eadb743df24b88334be7cb_orig.jpg', 'groundTruth': [{'bbox_2d': [372, 279, 546, 313], 'label': 'signatures'}, {'bbox_2d': [231, 282, 345, 315], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_30_png_jpg.rf.78b326c8f9122d57aa075fc6d4116543_orig.jpg', 'groundTruth': [{'bbox_2d': [487, 250, 552, 420], 'label': 'signatures'}]}, {'image_path': 'data/images/test_mta60c00_jpg.rf.79bbc2accdd556d94b274c2cfc2f6e27_orig.jpg', 'groundTruth': [{'bbox_2d': [408, 403, 486, 544], 'label': 'signatures'}]}, {'image_path': 'data/images/test_hzq96c00-first_jpg.rf.47db349ee859e36f1ad8255e562f48a9_orig.jpg', 'groundTruth': [{'bbox_2d': [374, 490, 434, 510], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sfp41a00-page5_2_jpg.rf.ad43b35c75d518d6fdc39fb5f25f397f_orig.jpg', 'groundTruth': [{'bbox_2d': [505, 397, 546, 526], 'label': 'signatures'}, {'bbox_2d': [531, 184, 576, 305], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_4_png_jpg.rf.77089a99492027b637284dbbb6809d2c_orig.jpg', 'groundTruth': [{'bbox_2d': [23, 18, 299, 139], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_12_jpg.rf.e391477ff59d15a62f2e44c8aff35dd0_orig.jpg', 'groundTruth': [{'bbox_2d': [329, 252, 399, 389], 'label': 'signatures'}, {'bbox_2d': [326, 90, 414, 254], 'label': 'signatures'}]}, {'image_path': 'data/images/test_tyr04d00_jpg.rf.c122650468875a0db73bfea7bbb097ba_orig.jpg', 'groundTruth': [{'bbox_2d': [53, 377, 103, 575], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_178_png_jpg.rf.2f779a9feb804fafedb666b764ba4a5e_orig.jpg', 'groundTruth': [{'bbox_2d': [122, 503, 340, 562], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_32_png_jpg.rf.5b2d083c70ccbe58f94652b67f568a31_orig.jpg', 'groundTruth': [{'bbox_2d': [325, 530, 575, 596], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_68_png_jpg.rf.4f58cf07a36896c3afadb0198d68773c_orig.jpg', 'groundTruth': [{'bbox_2d': [458, 25, 587, 235], 'label': 'signatures'}]}, {'image_path': 'data/images/test_yeo49d00-page02_2_jpg.rf.03ed801e919fd1887eaa657c987108c2_orig.jpg', 'groundTruth': [{'bbox_2d': [318, 122, 458, 158], 'label': 'signatures'}, {'bbox_2d': [330, 182, 535, 209], 'label': 'signatures'}, {'bbox_2d': [326, 84, 464, 110], 'label': 'signatures'}]}, {'image_path': 'data/images/test_qit05f00-page2_8_jpg.rf.d64733f5e0966a5de7fd75198a534dad_orig.jpg', 'groundTruth': [{'bbox_2d': [379, 296, 475, 340], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_167_png_jpg.rf.f9fa0ba2170d84e1b8e1c8545e6b963d_orig.jpg', 'groundTruth': [{'bbox_2d': [517, 95, 601, 291], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_8_png_jpg.rf.43de58a4fd63fc2ebdbecf15f4a774fe_orig.jpg', 'groundTruth': [{'bbox_2d': [32, 188, 181, 250], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xmw13f00_jpg.rf.95b71e6c5ae75a079f2fda683a923074_orig.jpg', 'groundTruth': [{'bbox_2d': [194, 349, 239, 533], 'label': 'signatures'}]}, {'image_path': 'data/images/test_aex05f00_1_jpg.rf.1f61f77d06f7b213069cc9fb952b5951_orig.jpg', 'groundTruth': [{'bbox_2d': [341, 129, 404, 309], 'label': 'signatures'}]}, {'image_path': 'data/images/test_khz25e00_jpg.rf.a6a70e1a55bc3725ac96c30f2e49bd7a_orig.jpg', 'groundTruth': [{'bbox_2d': [128, 73, 205, 296], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ydx05f00_jpg.rf.407f6abb7f64fb2e6f0cec78f8ec2544_orig.jpg', 'groundTruth': [{'bbox_2d': [310, 291, 490, 334], 'label': 'signatures'}, {'bbox_2d': [60, 555, 133, 595], 'label': 'signatures'}]}, {'image_path': 'data/images/test_bia05a00_jpg.rf.d5c7731182c0196cce2f3b6ad60a73e8_orig.jpg', 'groundTruth': [{'bbox_2d': [316, 449, 447, 480], 'label': 'signatures'}]}, {'image_path': 'data/images/test_pzb89c00_jpg.rf.57fba401e9a7d82c7dc541300501939a_orig.jpg', 'groundTruth': [{'bbox_2d': [87, 375, 181, 401], 'label': 'signatures'}]}, {'image_path': 'data/images/test_avb45e00_jpg.rf.990a61cde580eeb6eb1e3e9d1c778a59_orig.jpg', 'groundTruth': [{'bbox_2d': [287, 491, 470, 531], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_65_png_jpg.rf.8c32baab7280755d147f6b63ad1c00b1_orig.jpg', 'groundTruth': [{'bbox_2d': [220, 56, 280, 181], 'label': 'signatures'}]}, {'image_path': 'data/images/test_zlw44e00-page02_2_jpg.rf.54ed94880632a06c54676339615cf09c_orig.jpg', 'groundTruth': [{'bbox_2d': [297, 243, 388, 283], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_121_png_jpg.rf.01650831f2139b584dea1f96c9c676e3_orig.jpg', 'groundTruth': [{'bbox_2d': [609, 460, 639, 563], 'label': 'signatures'}]}, {'image_path': 'data/images/test_chw80e00_1_jpg.rf.93cdde06b7b608c0a9126d849b404ced_orig.jpg', 'groundTruth': [{'bbox_2d': [262, 390, 306, 488], 'label': 'signatures'}]}, {'image_path': 'data/images/test_gvz52d00-page02_2_jpg.rf.3648ddc7d02a4a953e21473ef8f76196_orig.jpg', 'groundTruth': [{'bbox_2d': [379, 341, 428, 407], 'label': 'signatures'}]}, {'image_path': 'data/images/test_spg81c00_jpg.rf.e860c64a72dd445f406ec8958b85edc9_orig.jpg', 'groundTruth': [{'bbox_2d': [94, 493, 173, 519], 'label': 'signatures'}]}, {'image_path': 'data/images/test_byd23a00_jpg.rf.fbb5e8d41ed07dc4f2b3fa30368768c2_orig.jpg', 'groundTruth': [{'bbox_2d': [309, 282, 420, 319], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_25_jpg.rf.d0461ae6596c8f2005296083b439abe0_orig.jpg', 'groundTruth': [{'bbox_2d': [370, 65, 442, 260], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ewe36d00_jpg.rf.3be8e7337faae434367e68749c36fbba_orig.jpg', 'groundTruth': [{'bbox_2d': [85, 352, 259, 396], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_79_png_jpg.rf.52049675c55f51622cab40d2021a0577_orig.jpg', 'groundTruth': [{'bbox_2d': [211, 284, 329, 457], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_118_png_jpg.rf.251cdcec156d1287ab1106fabdd992cd_orig.jpg', 'groundTruth': [{'bbox_2d': [95, 97, 290, 189], 'label': 'signatures'}]}, {'image_path': 'data/images/test_wau30a00-page9_5_jpg.rf.9f8a164f68d0934faf3de5ecde53485d_orig.jpg', 'groundTruth': [{'bbox_2d': [385, 464, 560, 499], 'label': 'signatures'}, {'bbox_2d': [186, 299, 366, 341], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_186_png_jpg.rf.7a2cefff3f97187690e898da0d566d45_orig.jpg', 'groundTruth': [{'bbox_2d': [501, 9, 569, 149], 'label': 'signatures'}]}, {'image_path': 'data/images/test_sla48c00_jpg.rf.2f6336a12bdeadce125103b6692a20fe_orig.jpg', 'groundTruth': [{'bbox_2d': [22, 453, 246, 482], 'label': 'signatures'}, {'bbox_2d': [293, 448, 471, 493], 'label': 'signatures'}]}, {'image_path': 'data/images/test_oan00d00_jpg.rf.596d73364b562e3e7856a1f30fa6b72b_orig.jpg', 'groundTruth': [{'bbox_2d': [184, 179, 353, 232], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_173_png_jpg.rf.9ef436daf635475ad8ae30873ffa557d_orig.jpg', 'groundTruth': [{'bbox_2d': [513, 418, 548, 591], 'label': 'signatures'}, {'bbox_2d': [505, 86, 580, 241], 'label': 'signatures'}]}, {'image_path': 'data/images/test_hls03f00_1_jpg.rf.560bb67b9b02bb7af8ab1e0dc330318b_orig.jpg', 'groundTruth': [{'bbox_2d': [160, 332, 179, 432], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_125_png_jpg.rf.4ea73faea8c3ef1738aaf52dd3f19d56_orig.jpg', 'groundTruth': [{'bbox_2d': [108, 224, 201, 383], 'label': 'signatures'}]}, {'image_path': 'data/images/test_djz54f00_jpg.rf.fce566867d00a0250232a2ad74015e89_orig.jpg', 'groundTruth': [{'bbox_2d': [357, 420, 495, 462], 'label': 'signatures'}]}, {'image_path': 'data/images/test_ukk18c00-page03_3_jpg.rf.503048f69517b19e823347f1606b4d4b_orig.jpg', 'groundTruth': [{'bbox_2d': [460, 405, 533, 429], 'label': 'signatures'}]}, {'image_path': 'data/images/test_xyb11c00-page2_2_jpg.rf.7bf80782d526752fc82464a924462f6d_orig.jpg', 'groundTruth': [{'bbox_2d': [283, 236, 488, 270], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_137_png_jpg.rf.3dd2b9b77c1fcbb754e1c5f06ae6bd82_orig.jpg', 'groundTruth': [{'bbox_2d': [350, 516, 469, 554], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_99_png_jpg.rf.6ae964485d272e442827d08a1e3dbf69_orig.jpg', 'groundTruth': [{'bbox_2d': [347, 509, 584, 578], 'label': 'signatures'}]}, {'image_path': 'data/images/test_image_178_png_jpg.rf.c3bdf1bfc5ef2e8df467f4d297e152cf_orig.jpg', 'groundTruth': [{'bbox_2d': [500, 305, 564, 525], 'label': 'signatures'}]}, {'image_path': 'data/images/test_dqn43c00_jpg.rf.b03d4a8f17a5d74ad62d76d05cfb5e4a_orig.jpg', 'groundTruth': [{'bbox_2d': [200, 95, 227, 210], 'label': 'signatures'}]}, {'image_path': 'data/images/test_cgy54f00_1_jpg.rf.e5704df553c7ed7e9d6b6363df19cf1c_orig.jpg', 'groundTruth': [{'bbox_2d': [383, 369, 480, 408], 'label': 'signatures'}]}, {'image_path': 'data/images/test_kcn64a00_jpg.rf.c01381271386a052307642f40ee4b337_orig.jpg', 'groundTruth': [{'bbox_2d': [85, 303, 152, 568], 'label': 'signatures'}]}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_json_path = 'data/test.jsonl'\n",
    "test_json = []\n",
    "\n",
    "with open(test_json_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data=json.loads(line)\n",
    "        image_path = 'data/'+data['image']\n",
    "        groundTruth = json.loads(data['label'])\n",
    "        test_json.append({\n",
    "                        'image_path': image_path,\n",
    "                        'groundTruth': groundTruth\n",
    "                        })\n",
    "\n",
    "# Now test_json is a list of dictionaries\n",
    "print(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c59066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ground_truth(Ground_T):\n",
    "    \"\"\"\n",
    "    Extracts GT boxes from Qwen format: <box>(y1,x1),(y2,x2)</box>\n",
    "    Returns list of [x1, y1, x2, y2] on 0-1000 scale.\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    for item in Ground_T:\n",
    "        label = item['label']\n",
    "        bbox = item['bbox_2d']\n",
    "        bboxes.append(bbox)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c0a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_and_scale_boxes(output_text, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Parses Qwen2.5-VL output (0-1000 scale) and converts to absolute pixels.\n",
    "    \n",
    "    Args:\n",
    "        output_text (str): The raw string output from the model.\n",
    "        img_width (int): Original width of the image.\n",
    "        img_height (int): Original height of the image.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dicts with scaled 'bbox_2d' [x1, y1, x2, y2] in pixels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Clean the output string to get pure JSON\n",
    "        # This handles cases where the model wraps code in ```json ... ```\n",
    "        if \"```json\" in output_text:\n",
    "            json_str = output_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in output_text:\n",
    "            json_str = output_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = output_text.strip()\n",
    "            \n",
    "        # 2. Parse JSON\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # 3. Scale Coordinates\n",
    "        scaled_results = []\n",
    "        for item in data:\n",
    "            if \"bbox_2d\" in item:\n",
    "                # Get the normalized 0-1000 coordinates\n",
    "                # Format is [xmin, ymin, xmax, ymax]\n",
    "                norm_box = item[\"bbox_2d\"]\n",
    "                \n",
    "                # Apply the scaling formula\n",
    "                abs_box = [\n",
    "                    (norm_box[0] / 1000.0) * img_width,   # xmin\n",
    "                    (norm_box[1] / 1000.0) * img_height,  # ymin\n",
    "                    (norm_box[2] / 1000.0) * img_width,   # xmax\n",
    "                    (norm_box[3] / 1000.0) * img_height   # ymax\n",
    "                ]\n",
    "                \n",
    "                # Create a new item with the scaled box\n",
    "                new_item = item.copy()\n",
    "                new_item[\"bbox_2d\"] = [int(x) for x in abs_box] # Optional: Convert to int for cleaner pixels\n",
    "                scaled_results.append(new_item)\n",
    "                \n",
    "        return scaled_results\n",
    "\n",
    "    except (json.JSONDecodeError, IndexError, KeyError) as e:\n",
    "        print(f\"Parsing Error: {e}\")\n",
    "        # Return empty list on failure so the pipeline doesn't crash\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "905c7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iou(boxA, boxB):\n",
    "    # Standard IoU calculation\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    return interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "\n",
    "def match_predictions_to_ground_truth(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Matches predictions to ground truths using greedy IoU strategy.\n",
    "    \n",
    "    Args:\n",
    "        pred_boxes (list): List of [xmin, ymin, xmax, ymax]\n",
    "        gt_boxes (list):   List of [xmin, ymin, xmax, ymax]\n",
    "        iou_threshold (float): Minimum IoU to consider a match valid\n",
    "        \n",
    "    Returns:\n",
    "        matches (list): List of dicts {'pred': box, 'gt': box, 'iou': float}\n",
    "        unmatched_preds (list): List of pred_boxes that matched nothing\n",
    "        unmatched_gts (list): List of gt_boxes that were missed\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    # pred_boxes = [box['bbox_2d'] for box in pred_boxes]\n",
    "    \n",
    "    # Keep track of which indices have been matched\n",
    "    matched_pred_indices = set()\n",
    "    matched_gt_indices = set()\n",
    "    \n",
    "    # 1. Calculate IoU for ALL pairs\n",
    "    # Format: (iou, pred_index, gt_index)\n",
    "    all_pairs = []\n",
    "    for i, p_box in enumerate(pred_boxes):\n",
    "        for j, g_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(p_box, g_box)\n",
    "            if iou > 0.0: # Only consider pairs that overlap at least a little\n",
    "                all_pairs.append((iou, i, j))\n",
    "    \n",
    "    # 2. Sort pairs by IoU (Highest first)\n",
    "    all_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # 3. Greedy Matching\n",
    "    for iou, p_idx, g_idx in all_pairs:\n",
    "        if p_idx not in matched_pred_indices and g_idx not in matched_gt_indices:\n",
    "            # Found the best remaining match!\n",
    "            if iou >= iou_threshold:\n",
    "                matches.append({\n",
    "                    'pred': pred_boxes[p_idx],\n",
    "                    'gt': gt_boxes[g_idx],\n",
    "                    'iou': iou\n",
    "                })\n",
    "                matched_pred_indices.add(p_idx)\n",
    "                matched_gt_indices.add(g_idx)\n",
    "    \n",
    "    # 4. Gather leftovers\n",
    "    unmatched_preds = [p for i, p in enumerate(pred_boxes) if i not in matched_pred_indices]\n",
    "    unmatched_gts = [g for i, g in enumerate(gt_boxes) if i not in matched_gt_indices]\n",
    "    \n",
    "    return matches, unmatched_preds, unmatched_gts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7727f",
   "metadata": {},
   "source": [
    "### Running the inference test on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f73ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'images': [<PIL.Image.Image image mode=RGB size=644x644 at 0x7FA79A27BCA0>], 'videos': None} not recognized.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InternVLModel' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m Ground_T \u001b[38;5;241m=\u001b[39m parse_ground_truth(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroundTruth\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m output_text, height, width \u001b[38;5;241m=\u001b[39m \u001b[43mzero_shot_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m height, width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(height), \u001b[38;5;28mint\u001b[39m(width)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(f\"Output Text: {output_text}\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#parsing of output\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mzero_shot_inference\u001b[0;34m(model, processor, image, prompt)\u001b[0m\n\u001b[1;32m     26\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Inference: Generation of the output\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     29\u001b[0m generated_ids_trimmed \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     30\u001b[0m     out_ids[\u001b[38;5;28mlen\u001b[39m(in_ids) :] \u001b[38;5;28;01mfor\u001b[39;00m in_ids, out_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs\u001b[38;5;241m.\u001b[39minput_ids, generated_ids)\n\u001b[1;32m     31\u001b[0m ]\n\u001b[1;32m     32\u001b[0m output_text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     33\u001b[0m     generated_ids_trimmed, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     34\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Object_detection_in_documents/venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InternVLModel' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "prompt = \"Detect all signatures and return their locations and labels in the form of coordinates. \"\n",
    "for item in test_json:\n",
    "    image_path = item['image_path']\n",
    "    Ground_T = parse_ground_truth(item['groundTruth'])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    output_text, height, width = zero_shot_inference(model, tokenizer, image, prompt)\n",
    "    height, width = int(height), int(width)\n",
    "    #print(f\"Output Text: {output_text}\")\n",
    "    #parsing of output\n",
    "    bbox_data_predict =parse_and_scale_boxes(output_text, image.width, image.height)\n",
    "    pred_boxes = [x['bbox_2d'] for x in bbox_data_predict if 'bbox_2d' in x]\n",
    "    print(f\"Predicted Bounding Boxes: {pred_boxes}\")\n",
    "    matches, false_positives, misses = match_predictions_to_ground_truth(pred_boxes, Ground_T, iou_threshold=0.1)\n",
    "    for match in matches:\n",
    "        # Use your detailed metric function here\n",
    "        metrics = evaluate_detection(match['pred'], match['gt'], img_width=width, img_height=height)\n",
    "        \n",
    "        # Store these specific metrics\n",
    "        # e.g., results.append(metrics)\n",
    "        print(f\"Matched with IoU: {metrics['iou']}, IoP: {metrics['iop']}, Center Dist: {metrics['center_dist_px']}px, Normalized Dist: {metrics['norm_center_dist']}\")\n",
    "\n",
    "    print(f\"False Positives (Hallucinations): {len(false_positives)}\")\n",
    "    print(f\"Missed Signatures: {len(misses)}\")   \n",
    "    plot_bounding_boxes(image, bbox_data_predict, image.height, image.width, Ground_T)\n",
    "    \n",
    "    break #single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e8eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def zero_shot_inference_internvl(model, tokenizer, image, prompt, max_num=12):\n",
    "    \"\"\"\n",
    "    Adapts your inference logic for InternVL models.\n",
    "    Note: InternVL typically uses a direct 'model.chat' method.\n",
    "    \"\"\"\n",
    "    # 1. Preprocess the image using the dynamic tiling logic\n",
    "    # This uses the load_image logic we discussed earlier\n",
    "    pixel_values = load_image_from_pil(image, max_num=max_num).to(torch.bfloat16).cuda()\n",
    "    \n",
    "    # 2. Define generation config\n",
    "    generation_config = dict(\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    # 3. InternVL Chat Interface\n",
    "    # The <image> token must be in the prompt for the model to 'see' the pixel_values\n",
    "    full_prompt = f'<image>\\n{prompt}'\n",
    "    \n",
    "    # model.chat handles the template, tokenization, and decoding internally\n",
    "    response = model.chat(\n",
    "        tokenizer, \n",
    "        pixel_values, \n",
    "        full_prompt, \n",
    "        generation_config\n",
    "    )\n",
    "\n",
    "    # 4. Calculate Input Height/Width \n",
    "    # InternVL scales images into tiles of 448x448.\n",
    "    # We can derive the 'canvas' size the model saw from the pixel_values shape.\n",
    "    # pixel_values shape is [num_tiles, 3, 448, 448]\n",
    "    num_tiles = pixel_values.size(0)\n",
    "    \n",
    "    # To get the exact resolution the model processed:\n",
    "    # We look at the target aspect ratio used during dynamic_preprocess\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(1, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= 1)\n",
    "    \n",
    "    # This helper gets the grid (e.g., 2x3 tiles)\n",
    "    from .your_script import find_closest_aspect_ratio # Assuming you kept the helper\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(aspect_ratio, target_ratios, orig_width, orig_height, 448)\n",
    "    \n",
    "    input_width = target_aspect_ratio[0] * 448\n",
    "    input_height = target_aspect_ratio[1] * 448\n",
    "\n",
    "    return response, input_height, input_width\n",
    "\n",
    "def load_image_from_pil(image, input_size=448, max_num=12):\n",
    "    \"\"\"Helper to process a PIL image directly instead of a file path\"\"\"\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(img) for img in images]\n",
    "    return torch.stack(pixel_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad0914",
   "metadata": {},
   "source": [
    "### Running the inference test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed38990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting evaluation on 257 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [10:58<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FINAL EVALUATION REPORT (257 Images)\n",
      "==================================================\n",
      "Total Matches Found:      277\n",
      "Total Missed Signatures:  43\n",
      "Total False Positives:    34\n",
      "--------------------------------------------------\n",
      "Mean IoU (Overlap):             0.5738\n",
      "Mean IoP (Tightness/Precision): 0.7272\n",
      "Mean Normalized Center Error:   0.0213 (2.13% of image diagonal)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Initialize Accumulators ---\n",
    "metrics_summary = {\n",
    "    \"iou\": [],\n",
    "    \"iop\": [],\n",
    "    \"norm_dist\": [],\n",
    "    \"false_positives\": 0,\n",
    "    \"missed_signatures\": 0,\n",
    "    \"total_images\": 0\n",
    "}\n",
    "\n",
    "prompt = \"Detect all signatures and return their locations and labels in the form of coordinates. \"\n",
    "\n",
    "print(f\">> Starting evaluation on {len(test_json)} images...\")\n",
    "\n",
    "# --- 2. Main Loop ---\n",
    "for item in tqdm(test_json):\n",
    "    image_path = item['image_path']\n",
    "    \n",
    "    # Load GT and Image\n",
    "    try:\n",
    "        Ground_T = parse_ground_truth(item['groundTruth']) # Ensure this returns list of [x1, y1, x2, y2]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        metrics_summary[\"total_images\"] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {image_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Inference\n",
    "    try:\n",
    "        output_text, height, width = zero_shot_inference(model, processor, image, prompt)\n",
    "                    \n",
    "        bbox_data_predict = parse_and_scale_boxes(output_text, image.width, image.height)\n",
    "\n",
    "        \n",
    "        # Extract just the boxes for matching [x1, y1, x2, y2]\n",
    "        # Assuming bbox_data_predict is list of dicts: [{'bbox_2d': [...], ...}]\n",
    "        pred_boxes = [x['bbox_2d'] for x in bbox_data_predict if 'bbox_2d' in x]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        pred_boxes = []\n",
    "\n",
    "    # Match Predictions to Ground Truth\n",
    "    matches, false_positives, misses = match_predictions_to_ground_truth(pred_boxes, Ground_T, iou_threshold=0.1)\n",
    "    \n",
    "    # Update Totals for FP / FN\n",
    "    metrics_summary[\"false_positives\"] += len(false_positives)\n",
    "    metrics_summary[\"missed_signatures\"] += len(misses)\n",
    "\n",
    "    # Collect Metrics for Matches\n",
    "    for match in matches:\n",
    "        # Evaluate using the normalized distance metric\n",
    "        m = evaluate_detection(match['pred'], match['gt'], img_width=width, img_height=height)\n",
    "        \n",
    "        metrics_summary[\"iou\"].append(m['iou'])\n",
    "        metrics_summary[\"iop\"].append(m['iop'])\n",
    "        metrics_summary[\"norm_dist\"].append(m['norm_center_dist'])\n",
    "\n",
    "# --- 3. Calculate Averages ---\n",
    "total_matches = len(metrics_summary[\"iou\"])\n",
    "\n",
    "if total_matches > 0:\n",
    "    avg_iou = sum(metrics_summary[\"iou\"]) / total_matches\n",
    "    avg_iop = sum(metrics_summary[\"iop\"]) / total_matches\n",
    "    avg_norm_dist = sum(metrics_summary[\"norm_dist\"]) / total_matches\n",
    "else:\n",
    "    avg_iou = avg_iop = avg_norm_dist = 0.0\n",
    "\n",
    "# --- 4. Final Report ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\" FINAL EVALUATION REPORT ({metrics_summary['total_images']} Images)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Matches Found:      {total_matches}\")\n",
    "print(f\"Total Missed Signatures:  {metrics_summary['missed_signatures']}\")\n",
    "print(f\"Total False Positives:    {metrics_summary['false_positives']}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mean IoU (Overlap):             {avg_iou:.4f}\")\n",
    "print(f\"Mean IoP (Tightness/Precision): {avg_iop:.4f}\")\n",
    "print(f\"Mean Normalized Center Error:   {avg_norm_dist:.4f} ({(avg_norm_dist*100):.2f}% of image diagonal)\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
